{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6__9sTPm6qdY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the input embedding tensor back from the file\n",
        "X = torch.load('/content/drive/My Drive/tensor.pth')\n",
        "\n",
        "# Check the loaded tensor\n",
        "print(X.size())\n",
        "\n",
        "#X = torch.load('/content/drive/My Drive/tensor.pth')\n",
        "#torch.Size([25000, 1000])"
      ],
      "metadata": {
        "id": "LdEFwCyM6xng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_label = torch.empty(25000, 1)\n",
        "label_count = 0\n",
        "\n",
        "#Colon_aca = 0  -> 5048\n",
        "#Colon_n = 1    -> 10048\n",
        "#lung_aca = 2   -> 15048\n",
        "#lung_n = 3     -> 20000\n",
        "#lung_scc = 4   -> 25000\n",
        "\n",
        "for i in range(25000):\n",
        "    if i < 5048:\n",
        "        input_label[i] = 0\n",
        "    elif i >= 5048 and i < 10048:\n",
        "        input_label[i] = 1\n",
        "    elif i >= 10048 and i < 15048:\n",
        "        input_label[i] = 2\n",
        "    elif i >= 15048 and i < 20000:\n",
        "        input_label[i] = 3\n",
        "    else:\n",
        "        input_label[i] = 4"
      ],
      "metadata": {
        "id": "chzo4EvC6xrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into Train and Test Datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, input_label, test_size = 0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "LQQaBJy-6xuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a Custome Dataset Class to Create Dataloaders\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "ObUoqv8_6xze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader instances for training and testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "5WUnd8ba7XDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of Train Loader: {len(train_loader)}\")\n",
        "print(f\"Size of Test Loader: {len(test_loader)}\")\n",
        "\n",
        "#Size of Train Loader: 625\n",
        "#Size of Test Loader: 157"
      ],
      "metadata": {
        "id": "wGVviq7y7XIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
        "train_features_batch.shape, train_labels_batch.shape\n",
        "\n",
        "#(torch.Size([32, 1000]), torch.Size([32, 1]))"
      ],
      "metadata": {
        "id": "KUGFWfzg7g4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Starting to create a Baseline model\n",
        "class CancerHistModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape: int,\n",
        "                 hidden_units: int,\n",
        "                 output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "            nn.Softmax(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "eJvKopgq7tWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embedding_shape = 1000\n",
        "hidden_units = 100\n",
        "output_shape = 5\n",
        "Model = CancerHistModel(input_shape=input_embedding_shape,\n",
        "                        hidden_units=hidden_units,\n",
        "                        output_shape=output_shape)\n",
        "Model\n",
        "\n",
        "# CancerHistModel(\n",
        "#   (layers): Sequential(\n",
        "#     (0): Linear(in_features=1000, out_features=100, bias=True)\n",
        "#     (1): ReLU()\n",
        "#     (2): Linear(in_features=100, out_features=100, bias=True)\n",
        "#     (3): Softmax(dim=None)\n",
        "#     (4): Linear(in_features=100, out_features=5, bias=True)\n",
        "#   )\n",
        "# )"
      ],
      "metadata": {
        "id": "1BWi343G7uaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy and LOSS FUNCTION DEFINITON FOR MODEL TRAINING\n",
        "def accuracy_fn(y_true,y_pred):\n",
        "  correct = torch.eq(y_true,y_pred).sum().item()\n",
        "  acc = (correct / y_true.numel())\n",
        "  return acc\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = Model.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "YjRRivY67uhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer\n",
        "\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  total_time = end=start\n",
        "  print(f\"toral time: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "PueCvT5V7-T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creting a training loop and training a model on Batches of data\n",
        "\n",
        "from tqdm.auto import tqdm #to get he progress bar\n",
        "import time\n",
        "\n",
        "#Set the seed the start the times\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = time.time\n",
        "\n",
        "#Set number of epochs\n",
        "epochs = 4\n",
        "\n",
        "#Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch} \\n---\")\n",
        "\n",
        "  #Training\n",
        "  train_loss = 0\n",
        "  #Add a loop to loop through training batches\n",
        "  for batch, (X,y) in enumerate (train_loader):\n",
        "    Model.train()\n",
        "\n",
        "    #Forward Pass\n",
        "    y_pred = Model(X)\n",
        "\n",
        "    # y = y.argmax(dim=1)\n",
        "    #Calculate loss\n",
        "    loss = loss_fn(y_pred,y.squeeze().long())\n",
        "    # print(f\"this is my calculates loss: {loss}\")\n",
        "    train_loss += loss\n",
        "\n",
        "    #Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    #Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #print out what's happeing\n",
        "    if batch%100 == 0:\n",
        "      print(f\"Lookd at { batch * len(X)}/{len(train_loader.dataset)} samples.\")\n",
        "\n",
        "  #Divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_loader)\n",
        "\n",
        "  #Testing\n",
        "  test_loss, test_acc = 0,0\n",
        "  Model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in test_loader:\n",
        "      test_pred = Model(X)\n",
        "      # y = y.argmax(dim=1)\n",
        "      test_loss += loss_fn(test_pred,y.squeeze().long())\n",
        "\n",
        "      test_acc += accuracy_fn(y_true=y,y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    #Calculate the test loss average per batch\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    #calculate test acc average per batch\n",
        "    test_acc /= len(test_loader)\n",
        "\n",
        "  print(f\"\\nTrain Loss {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.3f}\")\n",
        "  train_time_end_on_cpu = time.time"
      ],
      "metadata": {
        "id": "0DFfmElN8Bz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch: 0\n",
        "---\n",
        "Lookd at 0/20000 samples.\n",
        "Lookd at 3200/20000 samples.\n",
        "Lookd at 6400/20000 samples.\n",
        "Lookd at 9600/20000 samples.\n",
        "Lookd at 12800/20000 samples.\n",
        "Lookd at 16000/20000 samples.\n",
        "Lookd at 19200/20000 samples.\n",
        "\n",
        "Train Loss 0.9771 | Test loss: 0.6682, Test acc: 6.810\n",
        "Epoch: 1\n",
        "---\n",
        "Lookd at 0/20000 samples.\n",
        "Lookd at 3200/20000 samples.\n",
        "Lookd at 6400/20000 samples.\n",
        "Lookd at 9600/20000 samples.\n",
        "Lookd at 12800/20000 samples.\n",
        "Lookd at 16000/20000 samples.\n",
        "Lookd at 19200/20000 samples.\n",
        "\n",
        "Train Loss 0.6590 | Test loss: 0.6431, Test acc: 6.778\n",
        "Epoch: 2\n",
        "---\n",
        "Lookd at 0/20000 samples.\n",
        "Lookd at 3200/20000 samples.\n",
        "Lookd at 6400/20000 samples.\n",
        "Lookd at 9600/20000 samples.\n",
        "Lookd at 12800/20000 samples.\n",
        "Lookd at 16000/20000 samples.\n",
        "Lookd at 19200/20000 samples.\n",
        "\n",
        "Train Loss 0.6148 | Test loss: 0.5911, Test acc: 6.850\n",
        "Epoch: 3\n",
        "---\n",
        "Lookd at 0/20000 samples.\n",
        "Lookd at 3200/20000 samples.\n",
        "Lookd at 6400/20000 samples.\n",
        "Lookd at 9600/20000 samples.\n",
        "Lookd at 12800/20000 samples.\n",
        "Lookd at 16000/20000 samples.\n",
        "Lookd at 19200/20000 samples.\n",
        "\n",
        "Train Loss 0.5500 | Test loss: 0.5308, Test acc: 6.915\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "As it can be Observed here, both train and test loss decrease as number we train for more epochs but the test accuracy increases only slightly. This shows that Baseline Model is not able to perform a good job at classifying images for detection of cancer type and creates a accuracy of just 6.91%."
      ],
      "metadata": {
        "id": "c4d2Hf9t8HHK"
      }
    }
  ]
}